{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8b8b0b-1240-4f65-99f8-4cea8ec258a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ładowanie danych\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb5c5ee-56ca-42dc-aac6-b209578dafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacja danych\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbdcbd1-c473-4351-b5e4-5e985fc86f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwersja etykiet na typ int32\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "test_labels = test_labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac35f39-1b0d-475e-bc28-2b6a765fd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział danych na zestaw treningowy i walidacyjny\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.1, random_state=10, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3696444-565d-410f-bf7e-c78b14c6731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie zbioru typu Dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1000).batch(64)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725f5476-b05d-45bd-819d-40dd862ef3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wojciech\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "# Definicja modelu z dodatkowymi warstwami i regularizacją\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(300, activation='relu'),\n",
    "    layers.Dense(150, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae9c493-2838-4626-bcbd-542f850e15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilacja modelu\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a89151-f509-4d41-9ecd-b45f4c7f2ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7731 - loss: 0.6473 - val_accuracy: 0.8548 - val_loss: 0.3955\n",
      "Epoch 2/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8616 - loss: 0.3835 - val_accuracy: 0.8683 - val_loss: 0.3514\n",
      "Epoch 3/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8761 - loss: 0.3391 - val_accuracy: 0.8742 - val_loss: 0.3364\n",
      "Epoch 4/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8841 - loss: 0.3116 - val_accuracy: 0.8812 - val_loss: 0.3241\n",
      "Epoch 5/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8905 - loss: 0.2955 - val_accuracy: 0.8805 - val_loss: 0.3250\n",
      "Epoch 6/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8955 - loss: 0.2789 - val_accuracy: 0.8830 - val_loss: 0.3177\n",
      "Epoch 7/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9004 - loss: 0.2662 - val_accuracy: 0.8878 - val_loss: 0.3009\n",
      "Epoch 8/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9064 - loss: 0.2499 - val_accuracy: 0.8863 - val_loss: 0.3325\n",
      "Epoch 9/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.2397 - val_accuracy: 0.8908 - val_loss: 0.2976\n",
      "Epoch 10/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9143 - loss: 0.2276 - val_accuracy: 0.8898 - val_loss: 0.3076\n",
      "Epoch 11/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9164 - loss: 0.2211 - val_accuracy: 0.8917 - val_loss: 0.3071\n",
      "Epoch 12/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9205 - loss: 0.2122 - val_accuracy: 0.8932 - val_loss: 0.3132\n",
      "Epoch 13/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9231 - loss: 0.2035 - val_accuracy: 0.8955 - val_loss: 0.3064\n",
      "Epoch 14/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9256 - loss: 0.1920 - val_accuracy: 0.8955 - val_loss: 0.3132\n",
      "Epoch 15/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9288 - loss: 0.1852 - val_accuracy: 0.8943 - val_loss: 0.3324\n",
      "Epoch 16/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9315 - loss: 0.1788 - val_accuracy: 0.8928 - val_loss: 0.3709\n",
      "Epoch 17/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.1708 - val_accuracy: 0.8870 - val_loss: 0.3553\n",
      "Epoch 18/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9347 - loss: 0.1702 - val_accuracy: 0.8955 - val_loss: 0.3357\n",
      "Epoch 19/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.1605 - val_accuracy: 0.8982 - val_loss: 0.3597\n",
      "Epoch 20/20\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9416 - loss: 0.1529 - val_accuracy: 0.8902 - val_loss: 0.3786\n"
     ]
    }
   ],
   "source": [
    "# Trening modelu\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c059d4eb-ab06-4c38-9e88-dcd44d9b23ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.4288\n",
      "Test accuracy: 0.8828999996185303\n"
     ]
    }
   ],
   "source": [
    "# Ocena modelu na zestawie testowym\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa598428-e66e-4bcf-a37e-6993b983e21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Zapisanie modelu\n",
    "model.save('fashion_mnist_model.h5')\n",
    "\n",
    "# Ładowanie modelu\n",
    "loaded_model = tf.keras.models.load_model('fashion_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f35c40-475e-4db1-83d8-c79d2fc7e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_display(image, model):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    image = np.expand_dims(image, axis=0)  # Dodanie wymiaru batch\n",
    "    prediction = model.predict(image)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    print(f'Predicted label: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dc5a092-562b-4e0d-9a16-d1abab4a6bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "Predicted label: 9\n"
     ]
    }
   ],
   "source": [
    "sample_image = test_images[0]\n",
    "predict_and_display(sample_image, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa94a052-da13-437a-8fa2-d5c5a8136e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.12)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (1.13.1)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (0.24.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (4.11.0)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (2.7.2)\n",
      "Requirement already satisfied: albucore>=0.0.11 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (0.0.13)\n",
      "Requirement already satisfied: eval-type-backport in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (0.2.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (4.10.0.84)\n",
      "Requirement already satisfied: tomli>=2.0.1 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albucore>=0.0.11->albumentations) (2.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (2.18.3)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2.34.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2024.7.24)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\wojciech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c56d25-9658-49d6-b540-eefdad80ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from albumentations import HorizontalFlip, ShiftScaleRotate, RandomBrightnessContrast\n",
    "\n",
    "# Definiowanie transformacji augmentacyjnych\n",
    "transform = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    RandomBrightnessContrast(p=0.2)\n",
    "])\n",
    "\n",
    "def augment_images(images, labels):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    for img, lbl in zip(images, labels):\n",
    "        augmented = transform(image=img)\n",
    "        augmented_images.append(augmented['image'])\n",
    "        augmented_labels.append(lbl)\n",
    "    return np.array(augmented_images), np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "608c18b4-7eb9-49e0-9706-73d456791c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentacja danych treningowych\n",
    "augmented_X_train, augmented_y_train = augment_images(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdbce2d5-4361-4598-a984-32da6f5a7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie zbioru typu Dataset z danych augmentowanych\n",
    "augmented_train_ds = tf.data.Dataset.from_tensor_slices((augmented_X_train, augmented_y_train)).shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6206e46-d5da-457f-bd87-d8846b5b6430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7748 - loss: 0.6869 - val_accuracy: 0.8822 - val_loss: 0.3322\n",
      "Epoch 2/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8303 - loss: 0.4408 - val_accuracy: 0.8677 - val_loss: 0.3528\n",
      "Epoch 3/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 0.4053 - val_accuracy: 0.8842 - val_loss: 0.3194\n",
      "Epoch 4/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8543 - loss: 0.3759 - val_accuracy: 0.8847 - val_loss: 0.3314\n",
      "Epoch 5/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8635 - loss: 0.3544 - val_accuracy: 0.8893 - val_loss: 0.3216\n",
      "Epoch 6/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8711 - loss: 0.3320 - val_accuracy: 0.8813 - val_loss: 0.3664\n",
      "Epoch 7/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8770 - loss: 0.3165 - val_accuracy: 0.8863 - val_loss: 0.3616\n",
      "Epoch 8/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8848 - loss: 0.2987 - val_accuracy: 0.8895 - val_loss: 0.3591\n",
      "Epoch 9/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8859 - loss: 0.2879 - val_accuracy: 0.8942 - val_loss: 0.3591\n",
      "Epoch 10/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8937 - loss: 0.2739 - val_accuracy: 0.8873 - val_loss: 0.3889\n",
      "Epoch 11/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8983 - loss: 0.2649 - val_accuracy: 0.8788 - val_loss: 0.4332\n",
      "Epoch 12/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.2526 - val_accuracy: 0.8873 - val_loss: 0.4106\n",
      "Epoch 13/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.2478 - val_accuracy: 0.8777 - val_loss: 0.4218\n",
      "Epoch 14/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2350 - val_accuracy: 0.8878 - val_loss: 0.4144\n",
      "Epoch 15/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 0.2214 - val_accuracy: 0.8810 - val_loss: 0.4348\n",
      "Epoch 16/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9167 - loss: 0.2144 - val_accuracy: 0.8865 - val_loss: 0.4274\n",
      "Epoch 17/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9191 - loss: 0.2105 - val_accuracy: 0.8845 - val_loss: 0.4412\n",
      "Epoch 18/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.1997 - val_accuracy: 0.8878 - val_loss: 0.4175\n",
      "Epoch 19/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.1936 - val_accuracy: 0.8850 - val_loss: 0.4623\n",
      "Epoch 20/20\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9273 - loss: 0.1899 - val_accuracy: 0.8880 - val_loss: 0.4377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f12bbc5f70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ponowne trenowanie modelu na danych augmentowanych\n",
    "model.fit(augmented_train_ds, validation_data=val_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "371dbaf9-5cb4-46cd-bd80-98d592edb4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.5189\n",
      "Test accuracy after augmentation: 0.8787999749183655\n"
     ]
    }
   ],
   "source": [
    "# Ponowna ocena modelu na zestawie testowym\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy after augmentation: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb8257-1635-4b0d-8714-6812f03215f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Po kilkudziesięciu próbach\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy_kernel",
   "language": "python",
   "name": "numpy_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
